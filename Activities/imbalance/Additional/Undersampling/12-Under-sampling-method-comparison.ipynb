{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under-sampling Method Comparison\n",
    "\n",
    "\n",
    "We will compare how the different under-sampling algorithms discussed in this section improve (or not) the performance of Random Forests on different datasets with imbalanced classes.\n",
    "\n",
    "### Important\n",
    "\n",
    "- We train the models on a portion of the data that is under-sampled\n",
    "- We evaluate the model performance on another portion of the data that **was not resampled**, and thus contains the original class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from imblearn.datasets import fetch_datasets\n",
    "\n",
    "from imblearn.under_sampling import (\n",
    "    RandomUnderSampler,\n",
    "    CondensedNearestNeighbour,\n",
    "    TomekLinks,\n",
    "    OneSidedSelection,\n",
    "    EditedNearestNeighbours,\n",
    "    RepeatedEditedNearestNeighbours,\n",
    "    AllKNN,\n",
    "    NeighbourhoodCleaningRule,\n",
    "    NearMiss,\n",
    "    InstanceHardnessThreshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampler_dict = {\n",
    "\n",
    "    'random': RandomUnderSampler(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        replacement=False),\n",
    "\n",
    "    'cnn': CondensedNearestNeighbour(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        n_neighbors=1,\n",
    "        n_jobs=4),\n",
    "\n",
    "    'tomek': TomekLinks(\n",
    "        sampling_strategy='auto',\n",
    "        n_jobs=4),\n",
    "\n",
    "    'oss': OneSidedSelection(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        n_neighbors=1,\n",
    "        n_jobs=4),\n",
    "\n",
    "    'enn': EditedNearestNeighbours(\n",
    "        sampling_strategy='auto',\n",
    "        n_neighbors=3,\n",
    "        kind_sel='all',\n",
    "        n_jobs=4),\n",
    "\n",
    "    'renn': RepeatedEditedNearestNeighbours(\n",
    "        sampling_strategy='auto',\n",
    "        n_neighbors=3,\n",
    "        kind_sel='all',\n",
    "        n_jobs=4,\n",
    "        max_iter=100),\n",
    "\n",
    "    'allknn': AllKNN(\n",
    "        sampling_strategy='auto',\n",
    "        n_neighbors=3,\n",
    "        kind_sel='all',\n",
    "        n_jobs=4),\n",
    "\n",
    "    'ncr': NeighbourhoodCleaningRule(\n",
    "        sampling_strategy='auto',\n",
    "        n_neighbors=3,\n",
    "        # kind_sel='all',\n",
    "        n_jobs=4,\n",
    "        threshold_cleaning=0.5),\n",
    "\n",
    "    'nm1': NearMiss(\n",
    "        sampling_strategy='auto',\n",
    "        version=1,\n",
    "        n_neighbors=3,\n",
    "        n_jobs=4),\n",
    "\n",
    "    'nm2': NearMiss(\n",
    "        sampling_strategy='auto',\n",
    "        version=2,\n",
    "        n_neighbors=3,\n",
    "        n_jobs=4),\n",
    "\n",
    "    # here I set up a Logistic regression but remember\n",
    "    # that the authors of this technique concluded that it is best\n",
    "    # to use the same classifier that will be used to train the final\n",
    "    # model, so in our case, we should have used a Random Forest\n",
    "    'iht': InstanceHardnessThreshold(\n",
    "        estimator=LogisticRegression(random_state=0),\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        n_jobs=4,\n",
    "        cv=3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_ls = [\n",
    "    'car_eval_34',\n",
    "    'ecoli',\n",
    "    'thyroid_sick',\n",
    "    'arrhythmia',\n",
    "    'ozone_level'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print class imbalance for each dataset\n",
    "\n",
    "# this is to get a tiny bit familiar with the\n",
    "# datasets\n",
    "\n",
    "for dataset in datasets_ls:\n",
    "    data = fetch_datasets()[dataset]\n",
    "    print(dataset)\n",
    "    print(Counter(data.target))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train random forests and evaluate the performance\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100, random_state=39, max_depth=3, n_jobs=4,\n",
    "    )\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print(\n",
    "        'Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print(\n",
    "        'Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))\n",
    "    \n",
    "    # NOTE: that this function returns the ROC over the test set\n",
    "    # which is the portion of the data that would not be under-sampled\n",
    "    return roc_auc_score(y_test, pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop to train models with the different under-sampling methods\n",
    "# over the different datasets\n",
    "\n",
    "# to save the results\n",
    "results_dict = {}\n",
    "shapes_dict = {}\n",
    "\n",
    "# for each dataset\n",
    "for dataset in datasets_ls:\n",
    "    \n",
    "    # start a new dictionary per dataset\n",
    "    results_dict[dataset] = {}\n",
    "    shapes_dict[dataset] = {}\n",
    "    \n",
    "    print(dataset)\n",
    "    \n",
    "    # load dataset\n",
    "    data = fetch_datasets()[dataset]\n",
    "    \n",
    "    # separate train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.data,  \n",
    "        data.target, \n",
    "        test_size=0.3,\n",
    "        random_state=0,\n",
    "    )\n",
    "    \n",
    "    # as many undersampling techniques use KNN\n",
    "    # we put the variables in the same scale\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "        \n",
    "        \n",
    "    # train a model on the original data without under-sampling\n",
    "    # and determine model performance\n",
    "    roc = run_randomForests(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # store results\n",
    "    results_dict[dataset]['full_data'] = roc\n",
    "    shapes_dict[dataset]['full_data'] = len(X_train)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # now, we test the different under-samplers, 1 at a time\n",
    "    for undersampler in undersampler_dict.keys():\n",
    "        \n",
    "        print(undersampler)\n",
    "        \n",
    "        # resample the train set only\n",
    "        X_resampled, y_resampled = undersampler_dict[undersampler].fit_resample(X_train, y_train)\n",
    "        \n",
    "        # train model and evaluate performance\n",
    "        \n",
    "        # Note the performance returned is using the\n",
    "        # test set, which was not under-sampled\n",
    "        \n",
    "        roc = run_randomForests(X_resampled, X_test, y_resampled, y_test)\n",
    "        \n",
    "        # store results\n",
    "        results_dict[dataset][undersampler] = roc\n",
    "        shapes_dict[dataset][undersampler] = len(X_resampled)\n",
    "        print()\n",
    "        \n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the performance of the models trained with \n",
    "# the different under-sampling methods\n",
    "\n",
    "for dataset in datasets_ls:\n",
    "    \n",
    "    pd.Series(results_dict[dataset]).plot.bar()\n",
    "    plt.title(dataset)\n",
    "    plt.ylabel('roc-auc')\n",
    "#     plt.ylim(0.55, 0.9)\n",
    "    plt.axhline(results_dict[dataset]['full_data'], color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above but with a narrower scale for visibility\n",
    "\n",
    "for dataset in datasets_ls:\n",
    "    \n",
    "    pd.Series(results_dict[dataset]).plot.bar()\n",
    "    plt.title(dataset)\n",
    "    plt.ylabel('roc-auc')\n",
    "    \n",
    "    # this bit of code to modify the y axis scale\n",
    "    plt.ylim(0.8, 1)\n",
    "    \n",
    "    plt.axhline(results_dict[dataset]['full_data'], color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION**: Different under-sampling techniques work best for different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To finish, I plot the shapes of the datasets after the\n",
    "# different under-sampling methods were applied, for comparison\n",
    "\n",
    "# note that the fixed methods (undersampling, near miss and\n",
    "# instance hardness threshold) return the smallest datasets\n",
    "\n",
    "# and from the cleaning methods, the Condensed nearest neighbours are \n",
    "# the more aggressive at the time of removing samples from the data\n",
    "\n",
    "for dataset in datasets_ls:\n",
    "    \n",
    "    pd.Series(shapes_dict[dataset]).plot.bar()\n",
    "    plt.title(dataset)\n",
    "    plt.ylabel('Number of observations')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
