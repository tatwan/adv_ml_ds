{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Imbalanced Data: Condensed Nearest Neighbours (CNN) Undersampling\n",
    "\n",
    "## What is Imbalanced Data?\n",
    "\n",
    "Before diving into CNN, let's understand the problem we're solving:\n",
    "\n",
    "**Imbalanced data** occurs when one class (majority class) has significantly more observations than another class (minority class). This is extremely common in real-world scenarios:\n",
    "- Credit card fraud detection (99.9% legitimate, 0.1% fraudulent transactions)\n",
    "- Medical diagnosis (95% healthy, 5% diseased patients)\n",
    "- Email spam detection (90% legitimate, 10% spam emails)\n",
    "\n",
    "## Why is Imbalanced Data Problematic?\n",
    "\n",
    "1. **Bias towards majority class**: Machine learning algorithms tend to predict the majority class more often\n",
    "2. **Poor minority class detection**: Models struggle to identify the rare but often important minority class\n",
    "3. **Misleading accuracy**: A model that always predicts \"not fraud\" achieves 99.9% accuracy but catches 0% of actual fraud\n",
    "\n",
    "## Approaches to Handle Imbalanced Data\n",
    "\n",
    "There are several strategies:\n",
    "1. **Oversampling**: Increase minority class samples (SMOTE, ADASYN)\n",
    "2. **Undersampling**: Reduce majority class samples (Random, Tomek Links, **CNN**)\n",
    "3. **Hybrid methods**: Combine both approaches\n",
    "4. **Algorithm-level**: Use cost-sensitive learning or ensemble methods\n",
    "\n",
    "Today we'll focus on **Condensed Nearest Neighbours (CNN)**, a smart undersampling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condensed Nearest Neighbours (CNN)\n",
    "\n",
    "\n",
    "The algorithms works as follows:\n",
    "\n",
    "1) Put all minority class observations in a group, typically group O\n",
    "\n",
    "2) Add 1 sample (at random) from the majority class to group O\n",
    "\n",
    "3) Train a KNN with group O\n",
    "\n",
    "4) Take a sample of the majority class that is not in group O yet\n",
    "\n",
    "5) Predict its class with the KNN from point 3\n",
    "\n",
    "6) If the prediction was correct, go to 4 and repeat\n",
    "\n",
    "7) If the prediction was incorrect, add that sample to group O, go to 3 and repeat\n",
    "\n",
    "8) Continue until all samples of the majority class were either assigned to O or left out\n",
    "\n",
    "9) Final version of Group O is our undersampled dataset\n",
    "\n",
    "\n",
    "====\n",
    "\n",
    "- **Criteria for data exclusion**: Samples outside the boundary between the classes\n",
    "- **Final Dataset size**: varies\n",
    "\n",
    "====\n",
    "\n",
    "This algorithm tends to pick points near the fuzzy boundary between the classes, and transfer those to the group O, in our example. \n",
    "\n",
    "If the classes are similar, group O will contain a fair amount of both classes. If the classes are very different, group O would contain mostly 1 class, the minority class.\n",
    "\n",
    "**Caution:**\n",
    "\n",
    "- CNN tends to add noise to the undersampled dataset\n",
    "- Computationally expensive, because it trains 1 KNN every time an observation is added to the minority class group.\n",
    "\n",
    "In this notebook, we will first understand what Condensed Nearest Neigbours is doing with simulated data, and then compare its effect on model performance with real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Libraries We'll Use\n",
    "\n",
    "Let's import the essential libraries for our CNN exploration:\n",
    "\n",
    "- **pandas & matplotlib/seaborn**: For data manipulation and visualization\n",
    "- **sklearn.datasets.make_classification**: Creates synthetic imbalanced datasets for experimentation  \n",
    "- **sklearn.ensemble.RandomForestClassifier**: Our machine learning model for performance comparison\n",
    "- **sklearn.metrics.roc_auc_score**: Evaluation metric that works well with imbalanced data\n",
    "- **imblearn.under_sampling.CondensedNearestNeighbour**: The CNN implementation from imbalanced-learn library\n",
    "\n",
    "**Why ROC-AUC?** Unlike accuracy, ROC-AUC considers both true positive rate (sensitivity) and false positive rate, making it ideal for imbalanced datasets where we care about minority class detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data\n",
    "\n",
    "We will create data where the classes have different degrees of separateness.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(sep):\n",
    "    \n",
    "    # returns arrays\n",
    "    X, y = make_classification(n_samples=1000,\n",
    "                           n_features=2,\n",
    "                           n_redundant=0,\n",
    "                           n_clusters_per_class=1,\n",
    "                           weights=[0.99],\n",
    "                           class_sep=sep,# how separate the classes are\n",
    "                           random_state=1)\n",
    "    \n",
    "    # trasform arrays into pandas df and series\n",
    "    X = pd.DataFrame(X, columns =['varA', 'varB'])\n",
    "    y = pd.Series(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Synthetic Datasets for Learning\n",
    "\n",
    "Before working with real data, we'll create controlled synthetic datasets to understand how CNN behaves under different conditions.\n",
    "\n",
    "**Key Parameters in our data generation function:**\n",
    "- **n_samples=1000**: Total number of data points\n",
    "- **n_features=2**: Two features (varA, varB) so we can visualize easily\n",
    "- **weights=[0.99]**: Creates severe imbalance - 99% majority class, 1% minority class\n",
    "- **class_sep**: Controls how separable the classes are (this is what we'll experiment with)\n",
    "\n",
    "**Why start with synthetic data?** \n",
    "1. We can control the exact conditions and see how CNN responds\n",
    "2. We can visualize the results in 2D space\n",
    "3. We understand the \"ground truth\" of class separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make datasets with different class separateness\n",
    "# and plot\n",
    "\n",
    "for sep in [0.1, 1, 2]:\n",
    "    \n",
    "    X, y = make_data(sep)\n",
    "    \n",
    "    print(y.value_counts())\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=X, x=\"varA\", y=\"varB\", hue=y\n",
    "    )\n",
    "    \n",
    "    plt.title('Separation: {}'.format(sep))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Different Degrees of Class Separation\n",
    "\n",
    "Let's see how our classes look with different separation values:\n",
    "\n",
    "- **sep=0.1**: Classes heavily overlap (very difficult to separate)\n",
    "- **sep=1.0**: Classes partially overlap (moderate difficulty)  \n",
    "- **sep=2.0**: Classes well separated (easier to distinguish)\n",
    "\n",
    "**What to observe:**\n",
    "1. Class imbalance: Notice the tiny minority class (orange/class 1) vs. large majority class (blue/class 0)\n",
    "2. Separation effects: How overlap changes with different separation values\n",
    "3. Decision boundary complexity: Where would you draw a line to separate these classes?\n",
    "\n",
    "This visualization helps us understand why CNN's approach of focusing on boundary regions makes sense!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersample with Condensed Nearest Neighbours\n",
    "\n",
    "\n",
    "[CondensedNearestNeighbour](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.CondensedNearestNeighbour.html)\n",
    "\n",
    "\n",
    "### Well separated classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "\n",
    "X, y = make_data(sep=2)\n",
    "\n",
    "# set up condensed nearest neighbour transformer\n",
    "\n",
    "cnn = CondensedNearestNeighbour(\n",
    "    sampling_strategy='auto',  # undersamples only the majority class\n",
    "    random_state=0,  # for reproducibility\n",
    "    n_neighbors=1,# default\n",
    "    n_jobs=4)  # I have 4 cores in my laptop\n",
    "\n",
    "X_resampled, y_resampled = cnn.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying CNN to Well-Separated Classes\n",
    "\n",
    "Now let's see CNN in action! We'll start with well-separated classes (sep=2) to see the clearest example of how CNN works.\n",
    "\n",
    "**CNN Parameters explained:**\n",
    "- **sampling_strategy='auto'**: Only undersample the majority class (keeps all minority samples)\n",
    "- **random_state=0**: Ensures reproducible results for teaching\n",
    "- **n_neighbors=1**: Uses 1-NN for boundary detection (can be adjusted)\n",
    "- **n_jobs=4**: Uses multiple CPU cores for faster processing\n",
    "\n",
    "**What CNN will do:**\n",
    "1. Start with all minority class samples (these are precious, don't remove any!)\n",
    "2. Add one random majority class sample\n",
    "3. Train a KNN classifier\n",
    "4. Test remaining majority samples - keep those that are misclassified (near boundary)\n",
    "5. Repeat until all majority samples are processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of original data\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of undersampled data\n",
    "\n",
    "X_resampled.shape, y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of minority class observations\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Results: Data Size Changes\n",
    "\n",
    "Let's examine what happened to our dataset size after CNN undersampling:\n",
    "\n",
    "**Key observations to make:**\n",
    "1. **Original dataset**: 1000 samples with severe imbalance\n",
    "2. **Undersampled dataset**: Significantly reduced size, but better balance\n",
    "3. **Minority class preservation**: CNN keeps ALL minority class samples (this is crucial!)\n",
    "4. **Majority class reduction**: Only keeps the \"informative\" majority class samples\n",
    "\n",
    "**Why this matters**: CNN doesn't randomly throw away majority class samples. It intelligently selects only those that are close to the decision boundary, preserving the most informative samples for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=X, x=\"varA\", y=\"varB\", hue=y\n",
    ")\n",
    "\n",
    "plt.title('Original dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot undersampled data\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=X_resampled, x=\"varA\", y=\"varB\", hue=y_resampled\n",
    ")\n",
    "\n",
    "plt.title('Undersampled dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Comparison: Before and After CNN\n",
    "\n",
    "Now comes the most important part - visualizing what CNN actually selected!\n",
    "\n",
    "**What to look for in the comparison:**\n",
    "\n",
    "**Original dataset:**\n",
    "- Massive majority class (blue) scattered throughout the space\n",
    "- Tiny minority class (orange) clustered in one region\n",
    "- Clear separation between classes\n",
    "\n",
    "**After CNN undersampling:**\n",
    "- Much smaller majority class representation\n",
    "- Same minority class (CNN never touches minority samples)\n",
    "- **Key insight**: Notice which majority class points were kept - they're the ones closest to the minority class region!\n",
    "\n",
    "**The CNN \"intelligence\"**: CNN kept only the majority class samples that are near the decision boundary. The isolated majority class samples (far from minorities) were removed as \"redundant\" - they don't help distinguish between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condensed Nearest Neighbours retains the observations from the majority class, that are more similar to those in the minority class.\n",
    "\n",
    "**Note how values bigger where varA > 3, and varB >3 have not been included in the undersampled dataset**\n",
    "\n",
    "### Partially separated classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "X, y = make_data(sep=0.5)\n",
    "\n",
    "# set up condensed nearest neighbour transformer\n",
    "\n",
    "cnn = CondensedNearestNeighbour(\n",
    "    sampling_strategy='auto',  # undersamples only the majority class\n",
    "    random_state=0,  # for reproducibility\n",
    "    n_neighbors=1,\n",
    "    n_jobs=4)  # I have 4 cores in my laptop\n",
    "\n",
    "X_resampled, y_resampled = cnn.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing CNN with Partially Separated Classes\n",
    "\n",
    "Now let's see how CNN behaves when classes are harder to separate (sep=0.5). This is more realistic - real-world classes often overlap significantly.\n",
    "\n",
    "**Hypothesis**: When classes overlap more, CNN should:\n",
    "1. Keep MORE majority class samples (because more are near the boundary)\n",
    "2. Result in a LARGER undersampled dataset\n",
    "3. Preserve more complex decision boundary information\n",
    "\n",
    "**Why this experiment matters**: Well-separated classes are easy for any classifier. The real test is how methods perform when classes overlap - this is where CNN's boundary-focused approach should shine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampled data\n",
    "\n",
    "X_resampled.shape, y_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that more samples were included in the final training set, compared to the previous case where classes were more separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=X, x=\"varA\", y=\"varB\", hue=y\n",
    ")\n",
    "\n",
    "plt.title('Original dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot undersampled data\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=X_resampled, x=\"varA\", y=\"varB\", hue=y_resampled\n",
    ")\n",
    "\n",
    "plt.title('Undersampled dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Results: Well-Separated vs. Overlapping Classes\n",
    "\n",
    "**Key Learning Moment**: Compare the dataset sizes and visualizations between well-separated (sep=2) and overlapping (sep=0.5) classes.\n",
    "\n",
    "**What you should observe:**\n",
    "1. **Dataset size difference**: The overlapping classes resulted in a larger undersampled dataset\n",
    "2. **More retained samples**: More majority class points were kept when classes overlapped\n",
    "3. **Boundary complexity**: The decision boundary is more complex when classes overlap\n",
    "\n",
    "**CNN's adaptive behavior**: CNN automatically adjusts to data complexity:\n",
    "- Simple, well-separated data → Aggressive undersampling (small final dataset)\n",
    "- Complex, overlapping data → Conservative undersampling (larger final dataset)\n",
    "\n",
    "This is why CNN is considered \"intelligent\" undersampling - it adapts to your data's characteristics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note again, how CNN preserves the observations from the majority class that look more similar to those in the minority class.\n",
    "\n",
    "**HOMEWORK**\n",
    "\n",
    "- Although CNN was originally developed using 1 KNN, try changing the number of neighbours and compare the sizes of the undersampled datasets and the distribution of the observations in the plots.\n",
    "\n",
    "===\n",
    "\n",
    "\n",
    "## Condensed Nearest Neighbours\n",
    "\n",
    "### Real data - Performance comparison\n",
    "\n",
    "Does it work well with real datasets? \n",
    "\n",
    "Well, it will depend on the dataset, so we need to try and compare the models built on the whole dataset, and that built on the undersampled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# only a few observations to speed the computaton\n",
    "\n",
    "data = pd.read_csv('../kdd2004.csv').sample(10000)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transitioning to Real-World Data\n",
    "\n",
    "Now that we understand CNN's behavior with controlled synthetic data, let's test it on real data where:\n",
    "1. **We don't control the class separation**\n",
    "2. **We have many more features** (not just 2D)\n",
    "3. **The patterns are more complex** and realistic\n",
    "4. **We care about actual predictive performance**\n",
    "\n",
    "**Important considerations for real data:**\n",
    "- CNN can be computationally expensive (trains many KNN models)\n",
    "- Real data may have noise that CNN could amplify\n",
    "- Performance gains aren't guaranteed - it depends on your specific dataset\n",
    "\n",
    "**The critical question**: Does CNN's intelligent boundary-focused undersampling translate to better machine learning performance on real problems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced target\n",
    "data.target.value_counts() / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),  # drop the target\n",
    "    data['target'],  # just the target\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is going to take a while\n",
    "\n",
    "cnn = CondensedNearestNeighbour(\n",
    "    sampling_strategy='auto',  # sundersamples only the majority class\n",
    "    random_state=0,  # for reproducibility\n",
    "    n_neighbors=1,\n",
    "    n_jobs=4) \n",
    "\n",
    "X_resampled, y_resampled = cnn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying CNN to Real Data: Patience Required!\n",
    "\n",
    "**⚠️ Performance Warning**: CNN is computationally intensive because:\n",
    "1. **Multiple KNN trainings**: One KNN model for each candidate majority sample\n",
    "2. **Iterative process**: Each addition requires retraining\n",
    "3. **Distance calculations**: KNN requires computing distances to all training points\n",
    "\n",
    "**Why it takes time**: For each majority class sample, CNN must:\n",
    "- Train a KNN on current selected samples\n",
    "- Predict the class of the candidate sample\n",
    "- Decide whether to include it based on prediction accuracy\n",
    "\n",
    "**In production**: Consider using CNN on a representative sample first, or use faster alternatives like Random Undersampling for initial experiments.\n",
    "\n",
    "**The trade-off**: Computational cost vs. intelligent sample selection - CNN's smart selection often justifies the wait!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of undersampled data\n",
    "\n",
    "X_resampled.shape, y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of positive class in original dataset\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot data\n",
    "\n",
    "Let's compare how the data looks before and after the undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "sns.scatterplot(data=X_train,\n",
    "                x=\"0\",\n",
    "                y=\"1\",\n",
    "                hue=y_train)\n",
    "\n",
    "plt.title('Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampled data\n",
    "\n",
    "sns.scatterplot(data=X_resampled,\n",
    "                x=\"0\",\n",
    "                y=\"1\",\n",
    "                hue=y_resampled)\n",
    "\n",
    "plt.title('Undersampled data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Real Data: Understanding CNN's Selections\n",
    "\n",
    "**Challenge with high-dimensional data**: We can only visualize 2 features at a time, but our dataset has many more features. CNN makes decisions based on ALL features, not just the two we're plotting.\n",
    "\n",
    "**What to look for in these plots:**\n",
    "1. **Distribution changes**: How the class balance changes after undersampling\n",
    "2. **Pattern preservation**: Whether important data patterns are maintained\n",
    "3. **Boundary regions**: CNN should keep samples near class boundaries (where classes mix)\n",
    "\n",
    "**Important caveat**: These 2D projections don't show the full picture. CNN operates in the full feature space, so some selections might look odd in 2D but make perfect sense in higher dimensions.\n",
    "\n",
    "**Learning objective**: Focus on understanding the overall pattern of how CNN transforms the dataset rather than individual point selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "sns.scatterplot(data=X_train,\n",
    "                x=\"4\",\n",
    "                y=\"5\",\n",
    "                hue=y_train)\n",
    "\n",
    "plt.title('Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=X_resampled,\n",
    "                x=\"4\",\n",
    "                y=\"5\",\n",
    "                hue=y_resampled)\n",
    "\n",
    "plt.title('Undersampled data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning performance comparison\n",
    "\n",
    "Let's compare model performance with and without undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train random forests and evaluate the performance\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Ultimate Test: Machine Learning Performance\n",
    "\n",
    "This is where theory meets practice! We'll train identical Random Forest models on:\n",
    "1. **Original imbalanced data** (baseline performance)\n",
    "2. **CNN undersampled data** (testing CNN's effectiveness)\n",
    "\n",
    "**Our evaluation setup**:\n",
    "- **Random Forest**: Robust, popular algorithm that works well with tabular data\n",
    "- **ROC-AUC score**: Perfect for imbalanced classification (considers both classes equally)\n",
    "- **Train/Test split**: Ensures fair comparison and prevents overfitting\n",
    "\n",
    "**What we're testing**:\n",
    "- Does CNN's intelligent sample selection improve model performance?\n",
    "- Is the computational cost of CNN justified by better results?\n",
    "- How much performance gain (if any) do we get from CNN vs. original data?\n",
    "\n",
    "**Success criteria**: CNN should improve the model's ability to distinguish between classes, reflected in higher ROC-AUC scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance of algorithm built\n",
    "# using imbalanced dataset\n",
    "\n",
    "run_randomForests(X_train,\n",
    "                  X_test,\n",
    "                  y_train,\n",
    "                  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance of algorithm built\n",
    "# using undersampled dataset\n",
    "\n",
    "run_randomForests(X_resampled,\n",
    "                  X_test,\n",
    "                  y_resampled,\n",
    "                  y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis: Interpreting the Results\n",
    "\n",
    "**How to interpret ROC-AUC scores**:\n",
    "- **0.5**: Random guessing (no better than coin flip)\n",
    "- **0.6-0.7**: Poor performance \n",
    "- **0.7-0.8**: Fair performance\n",
    "- **0.8-0.9**: Good performance\n",
    "- **0.9-1.0**: Excellent performance\n",
    "\n",
    "**Key comparisons to make**:\n",
    "1. **Training vs. Testing**: Check for overfitting (big gap indicates overfitting)\n",
    "2. **Original vs. CNN**: Did CNN improve performance on the test set?\n",
    "3. **Practical significance**: Is the improvement worth the computational cost?\n",
    "\n",
    "**What good results look like**:\n",
    "- CNN test score > Original test score\n",
    "- Similar training and testing scores (no overfitting)\n",
    "- Meaningful improvement (not just 0.01 difference)\n",
    "\n",
    "**If CNN doesn't help**: That's also valuable learning! Not all datasets benefit from CNN - it depends on the nature of your class boundaries and data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways and Next Steps\n",
    "\n",
    "**What we learned about CNN**:\n",
    "1. **Intelligent selection**: CNN doesn't randomly remove samples - it focuses on class boundaries\n",
    "2. **Adaptive behavior**: Keeps more samples when classes overlap, fewer when well-separated  \n",
    "3. **Computational trade-off**: More expensive than random undersampling but potentially more effective\n",
    "4. **Performance varies**: Effectiveness depends on your specific dataset and problem\n",
    "\n",
    "**When to consider CNN**:\n",
    "✅ **Good for**: Datasets with clear class boundaries, sufficient computational resources  \n",
    "✅ **Good for**: When you need to preserve minority class information completely  \n",
    "✅ **Good for**: Complex datasets where boundary regions are crucial  \n",
    "\n",
    "⚠️ **Be cautious with**: Very noisy datasets (CNN might preserve noise)  \n",
    "⚠️ **Be cautious with**: Time-constrained projects (can be slow)  \n",
    "⚠️ **Be cautious with**: Very high-dimensional data (curse of dimensionality affects KNN)\n",
    "\n",
    "**Alternative undersampling methods to explore**:\n",
    "- **Random Undersampling**: Fast baseline\n",
    "- **Tomek Links**: Removes overlapping samples  \n",
    "- **Edited Nearest Neighbours**: Removes misclassified samples\n",
    "- **OneSidedSelection**: Combines multiple strategies\n",
    "\n",
    "**HOMEWORK**\n",
    "\n",
    "- Try changing the number of neighbours used to select the observations from the majority class and with different machine learning models. Compare final dataset size, model performance and the distributions of the observations before and after the undersampling.\n",
    "- **Extension**: Compare CNN with other undersampling techniques on the same dataset\n",
    "- **Challenge**: Test CNN on different types of imbalanced problems (text classification, image classification, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsml",
   "language": "python",
   "name": "fsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
